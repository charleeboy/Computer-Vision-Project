{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "conditional-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "inner-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trainiter and testier\n",
    "\n",
    "trainloader = torch.load('../../1_Data_Loader/Data_Loader_files/trainloader_V1_resnet18.pt')\n",
    "testloader = torch.load('../../1_Data_Loader/Data_Loader_files/testloader_V1_resnet18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "civilian-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224]) 16\n"
     ]
    }
   ],
   "source": [
    "# testing the trainloader\n",
    "train_examples = iter(trainloader)\n",
    "train_samples, train_labels = train_examples.next()\n",
    "print(train_samples.shape, len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bulgarian-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224]) tensor([1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# testing the testloader\n",
    "test_examples = iter(testloader)\n",
    "test_samples, test_labels = test_examples.next()\n",
    "print(test_samples.shape, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "chinese-fortune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting GPU if it's available\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "satellite-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing resnet18\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "intended-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(512, 10),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(10, 3),\n",
    "                                 nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "saved-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "alert-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5.. Train loss: 0.567.. Test loss: 1.210.. Test accuracy: 0.547\n",
      "Epoch 1/5.. Train loss: 0.566.. Test loss: 1.135.. Test accuracy: 0.552\n",
      "Epoch 1/5.. Train loss: 0.514.. Test loss: 0.877.. Test accuracy: 0.581\n",
      "Epoch 1/5.. Train loss: 0.413.. Test loss: 1.090.. Test accuracy: 0.555\n",
      "Epoch 1/5.. Train loss: 0.457.. Test loss: 1.332.. Test accuracy: 0.574\n",
      "Epoch 1/5.. Train loss: 0.480.. Test loss: 1.306.. Test accuracy: 0.571\n",
      "Epoch 1/5.. Train loss: 0.459.. Test loss: 0.894.. Test accuracy: 0.585\n",
      "Epoch 1/5.. Train loss: 0.445.. Test loss: 0.895.. Test accuracy: 0.572\n",
      "Epoch 1/5.. Train loss: 0.460.. Test loss: 1.295.. Test accuracy: 0.536\n",
      "Epoch 1/5.. Train loss: 0.631.. Test loss: 1.224.. Test accuracy: 0.592\n",
      "Epoch 1/5.. Train loss: 0.462.. Test loss: 1.237.. Test accuracy: 0.567\n",
      "Epoch 1/5.. Train loss: 0.667.. Test loss: 0.992.. Test accuracy: 0.535\n",
      "Epoch 1/5.. Train loss: 0.506.. Test loss: 0.887.. Test accuracy: 0.541\n",
      "Epoch 1/5.. Train loss: 0.396.. Test loss: 1.029.. Test accuracy: 0.594\n",
      "Epoch 1/5.. Train loss: 0.445.. Test loss: 1.387.. Test accuracy: 0.592\n",
      "Epoch 1/5.. Train loss: 0.472.. Test loss: 1.301.. Test accuracy: 0.545\n",
      "Epoch 1/5.. Train loss: 0.497.. Test loss: 0.782.. Test accuracy: 0.592\n",
      "Epoch 1/5.. Train loss: 0.525.. Test loss: 0.714.. Test accuracy: 0.597\n",
      "Epoch 1/5.. Train loss: 0.411.. Test loss: 0.919.. Test accuracy: 0.538\n",
      "Epoch 1/5.. Train loss: 0.555.. Test loss: 1.012.. Test accuracy: 0.586\n",
      "Epoch 1/5.. Train loss: 0.496.. Test loss: 1.390.. Test accuracy: 0.583\n",
      "Epoch 1/5.. Train loss: 0.461.. Test loss: 1.317.. Test accuracy: 0.570\n",
      "Epoch 1/5.. Train loss: 0.483.. Test loss: 1.075.. Test accuracy: 0.577\n",
      "Epoch 1/5.. Train loss: 0.325.. Test loss: 0.961.. Test accuracy: 0.584\n",
      "Epoch 1/5.. Train loss: 0.387.. Test loss: 1.091.. Test accuracy: 0.588\n",
      "Epoch 1/5.. Train loss: 0.520.. Test loss: 0.954.. Test accuracy: 0.602\n",
      "Epoch 1/5.. Train loss: 0.383.. Test loss: 0.882.. Test accuracy: 0.644\n",
      "Epoch 1/5.. Train loss: 0.374.. Test loss: 0.927.. Test accuracy: 0.643\n",
      "Epoch 1/5.. Train loss: 0.450.. Test loss: 1.168.. Test accuracy: 0.616\n",
      "Epoch 1/5.. Train loss: 0.449.. Test loss: 1.367.. Test accuracy: 0.631\n",
      "Epoch 1/5.. Train loss: 0.328.. Test loss: 1.194.. Test accuracy: 0.639\n",
      "Epoch 1/5.. Train loss: 0.328.. Test loss: 1.124.. Test accuracy: 0.654\n",
      "Epoch 1/5.. Train loss: 0.328.. Test loss: 1.113.. Test accuracy: 0.650\n",
      "Epoch 1/5.. Train loss: 0.380.. Test loss: 1.244.. Test accuracy: 0.633\n",
      "Epoch 1/5.. Train loss: 0.244.. Test loss: 1.274.. Test accuracy: 0.599\n",
      "Epoch 2/5.. Train loss: 0.216.. Test loss: 1.711.. Test accuracy: 0.541\n",
      "Epoch 2/5.. Train loss: 0.583.. Test loss: 1.608.. Test accuracy: 0.554\n",
      "Epoch 2/5.. Train loss: 0.900.. Test loss: 1.028.. Test accuracy: 0.635\n",
      "Epoch 2/5.. Train loss: 0.363.. Test loss: 0.915.. Test accuracy: 0.621\n",
      "Epoch 2/5.. Train loss: 0.380.. Test loss: 0.912.. Test accuracy: 0.627\n",
      "Epoch 2/5.. Train loss: 0.323.. Test loss: 1.090.. Test accuracy: 0.612\n",
      "Epoch 2/5.. Train loss: 0.473.. Test loss: 1.292.. Test accuracy: 0.617\n",
      "Epoch 2/5.. Train loss: 0.323.. Test loss: 1.182.. Test accuracy: 0.652\n",
      "Epoch 2/5.. Train loss: 0.260.. Test loss: 1.202.. Test accuracy: 0.640\n",
      "Epoch 2/5.. Train loss: 0.503.. Test loss: 0.859.. Test accuracy: 0.697\n",
      "Epoch 2/5.. Train loss: 0.360.. Test loss: 0.756.. Test accuracy: 0.683\n",
      "Epoch 2/5.. Train loss: 0.354.. Test loss: 0.850.. Test accuracy: 0.657\n",
      "Epoch 2/5.. Train loss: 0.319.. Test loss: 1.069.. Test accuracy: 0.587\n",
      "Epoch 2/5.. Train loss: 0.382.. Test loss: 1.129.. Test accuracy: 0.618\n",
      "Epoch 2/5.. Train loss: 0.278.. Test loss: 0.946.. Test accuracy: 0.692\n",
      "Epoch 2/5.. Train loss: 0.414.. Test loss: 1.172.. Test accuracy: 0.666\n",
      "Epoch 2/5.. Train loss: 0.259.. Test loss: 1.048.. Test accuracy: 0.689\n",
      "Epoch 2/5.. Train loss: 0.207.. Test loss: 1.093.. Test accuracy: 0.677\n",
      "Epoch 2/5.. Train loss: 0.295.. Test loss: 1.093.. Test accuracy: 0.690\n",
      "Epoch 2/5.. Train loss: 0.272.. Test loss: 1.200.. Test accuracy: 0.669\n",
      "Epoch 2/5.. Train loss: 0.384.. Test loss: 1.268.. Test accuracy: 0.675\n",
      "Epoch 2/5.. Train loss: 0.296.. Test loss: 1.021.. Test accuracy: 0.701\n",
      "Epoch 2/5.. Train loss: 0.244.. Test loss: 0.796.. Test accuracy: 0.714\n",
      "Epoch 2/5.. Train loss: 0.327.. Test loss: 0.859.. Test accuracy: 0.713\n",
      "Epoch 2/5.. Train loss: 0.252.. Test loss: 1.078.. Test accuracy: 0.676\n",
      "Epoch 2/5.. Train loss: 0.246.. Test loss: 1.090.. Test accuracy: 0.692\n",
      "Epoch 2/5.. Train loss: 0.261.. Test loss: 1.001.. Test accuracy: 0.706\n",
      "Epoch 2/5.. Train loss: 0.288.. Test loss: 1.280.. Test accuracy: 0.661\n",
      "Epoch 2/5.. Train loss: 0.432.. Test loss: 1.105.. Test accuracy: 0.682\n",
      "Epoch 2/5.. Train loss: 0.370.. Test loss: 1.179.. Test accuracy: 0.678\n",
      "Epoch 2/5.. Train loss: 0.332.. Test loss: 1.136.. Test accuracy: 0.681\n",
      "Epoch 2/5.. Train loss: 0.391.. Test loss: 0.936.. Test accuracy: 0.705\n",
      "Epoch 2/5.. Train loss: 0.326.. Test loss: 1.098.. Test accuracy: 0.671\n",
      "Epoch 2/5.. Train loss: 0.319.. Test loss: 1.448.. Test accuracy: 0.664\n",
      "Epoch 2/5.. Train loss: 0.338.. Test loss: 1.069.. Test accuracy: 0.694\n",
      "Epoch 3/5.. Train loss: 0.285.. Test loss: 0.911.. Test accuracy: 0.715\n",
      "Epoch 3/5.. Train loss: 0.355.. Test loss: 0.881.. Test accuracy: 0.707\n",
      "Epoch 3/5.. Train loss: 0.185.. Test loss: 1.007.. Test accuracy: 0.717\n",
      "Epoch 3/5.. Train loss: 0.281.. Test loss: 1.350.. Test accuracy: 0.655\n",
      "Epoch 3/5.. Train loss: 0.360.. Test loss: 0.964.. Test accuracy: 0.685\n",
      "Epoch 3/5.. Train loss: 0.286.. Test loss: 1.041.. Test accuracy: 0.683\n",
      "Epoch 3/5.. Train loss: 0.395.. Test loss: 1.284.. Test accuracy: 0.667\n",
      "Epoch 3/5.. Train loss: 0.303.. Test loss: 1.909.. Test accuracy: 0.648\n",
      "Epoch 3/5.. Train loss: 0.385.. Test loss: 1.783.. Test accuracy: 0.665\n",
      "Epoch 3/5.. Train loss: 0.267.. Test loss: 1.125.. Test accuracy: 0.702\n",
      "Epoch 3/5.. Train loss: 0.278.. Test loss: 1.064.. Test accuracy: 0.691\n",
      "Epoch 3/5.. Train loss: 0.348.. Test loss: 1.171.. Test accuracy: 0.688\n",
      "Epoch 3/5.. Train loss: 0.324.. Test loss: 1.026.. Test accuracy: 0.700\n",
      "Epoch 3/5.. Train loss: 0.342.. Test loss: 0.951.. Test accuracy: 0.711\n",
      "Epoch 3/5.. Train loss: 0.221.. Test loss: 1.107.. Test accuracy: 0.697\n",
      "Epoch 3/5.. Train loss: 0.210.. Test loss: 1.549.. Test accuracy: 0.654\n",
      "Epoch 3/5.. Train loss: 0.313.. Test loss: 1.520.. Test accuracy: 0.671\n",
      "Epoch 3/5.. Train loss: 0.239.. Test loss: 1.054.. Test accuracy: 0.712\n",
      "Epoch 3/5.. Train loss: 0.310.. Test loss: 0.961.. Test accuracy: 0.710\n",
      "Epoch 3/5.. Train loss: 0.186.. Test loss: 1.126.. Test accuracy: 0.667\n",
      "Epoch 3/5.. Train loss: 0.279.. Test loss: 1.137.. Test accuracy: 0.672\n",
      "Epoch 3/5.. Train loss: 0.278.. Test loss: 1.013.. Test accuracy: 0.714\n",
      "Epoch 3/5.. Train loss: 0.196.. Test loss: 1.141.. Test accuracy: 0.703\n",
      "Epoch 3/5.. Train loss: 0.326.. Test loss: 1.419.. Test accuracy: 0.670\n",
      "Epoch 3/5.. Train loss: 0.476.. Test loss: 1.088.. Test accuracy: 0.694\n",
      "Epoch 3/5.. Train loss: 0.288.. Test loss: 1.032.. Test accuracy: 0.687\n",
      "Epoch 3/5.. Train loss: 0.249.. Test loss: 1.028.. Test accuracy: 0.705\n",
      "Epoch 3/5.. Train loss: 0.417.. Test loss: 1.071.. Test accuracy: 0.704\n",
      "Epoch 3/5.. Train loss: 0.409.. Test loss: 1.084.. Test accuracy: 0.725\n",
      "Epoch 3/5.. Train loss: 0.256.. Test loss: 1.207.. Test accuracy: 0.704\n",
      "Epoch 3/5.. Train loss: 0.408.. Test loss: 1.492.. Test accuracy: 0.675\n",
      "Epoch 3/5.. Train loss: 0.297.. Test loss: 1.571.. Test accuracy: 0.662\n",
      "Epoch 3/5.. Train loss: 0.372.. Test loss: 1.307.. Test accuracy: 0.683\n",
      "Epoch 4/5.. Train loss: 0.336.. Test loss: 1.373.. Test accuracy: 0.664\n",
      "Epoch 4/5.. Train loss: 0.316.. Test loss: 1.123.. Test accuracy: 0.691\n",
      "Epoch 4/5.. Train loss: 0.263.. Test loss: 1.141.. Test accuracy: 0.710\n",
      "Epoch 4/5.. Train loss: 0.304.. Test loss: 1.301.. Test accuracy: 0.676\n",
      "Epoch 4/5.. Train loss: 0.194.. Test loss: 1.740.. Test accuracy: 0.671\n",
      "Epoch 4/5.. Train loss: 0.211.. Test loss: 1.822.. Test accuracy: 0.669\n",
      "Epoch 4/5.. Train loss: 0.260.. Test loss: 1.536.. Test accuracy: 0.697\n",
      "Epoch 4/5.. Train loss: 0.371.. Test loss: 1.335.. Test accuracy: 0.712\n",
      "Epoch 4/5.. Train loss: 0.345.. Test loss: 1.486.. Test accuracy: 0.688\n",
      "Epoch 4/5.. Train loss: 0.154.. Test loss: 1.668.. Test accuracy: 0.685\n",
      "Epoch 4/5.. Train loss: 0.265.. Test loss: 1.747.. Test accuracy: 0.675\n",
      "Epoch 4/5.. Train loss: 0.142.. Test loss: 1.570.. Test accuracy: 0.680\n",
      "Epoch 4/5.. Train loss: 0.373.. Test loss: 1.608.. Test accuracy: 0.698\n",
      "Epoch 4/5.. Train loss: 0.385.. Test loss: 1.384.. Test accuracy: 0.706\n",
      "Epoch 4/5.. Train loss: 0.314.. Test loss: 1.100.. Test accuracy: 0.711\n",
      "Epoch 4/5.. Train loss: 0.247.. Test loss: 0.900.. Test accuracy: 0.733\n",
      "Epoch 4/5.. Train loss: 0.248.. Test loss: 1.204.. Test accuracy: 0.704\n",
      "Epoch 4/5.. Train loss: 0.174.. Test loss: 1.505.. Test accuracy: 0.689\n",
      "Epoch 4/5.. Train loss: 0.360.. Test loss: 1.540.. Test accuracy: 0.684\n",
      "Epoch 4/5.. Train loss: 0.265.. Test loss: 1.489.. Test accuracy: 0.701\n",
      "Epoch 4/5.. Train loss: 0.259.. Test loss: 1.539.. Test accuracy: 0.703\n",
      "Epoch 4/5.. Train loss: 0.257.. Test loss: 1.246.. Test accuracy: 0.709\n",
      "Epoch 4/5.. Train loss: 0.441.. Test loss: 1.341.. Test accuracy: 0.684\n",
      "Epoch 4/5.. Train loss: 0.331.. Test loss: 1.582.. Test accuracy: 0.681\n",
      "Epoch 4/5.. Train loss: 0.317.. Test loss: 1.383.. Test accuracy: 0.696\n",
      "Epoch 4/5.. Train loss: 0.232.. Test loss: 1.371.. Test accuracy: 0.695\n",
      "Epoch 4/5.. Train loss: 0.215.. Test loss: 1.406.. Test accuracy: 0.698\n",
      "Epoch 4/5.. Train loss: 0.234.. Test loss: 1.531.. Test accuracy: 0.692\n",
      "Epoch 4/5.. Train loss: 0.228.. Test loss: 1.297.. Test accuracy: 0.711\n",
      "Epoch 4/5.. Train loss: 0.418.. Test loss: 1.284.. Test accuracy: 0.708\n",
      "Epoch 4/5.. Train loss: 0.142.. Test loss: 1.545.. Test accuracy: 0.665\n",
      "Epoch 4/5.. Train loss: 0.340.. Test loss: 1.507.. Test accuracy: 0.679\n",
      "Epoch 4/5.. Train loss: 0.227.. Test loss: 1.170.. Test accuracy: 0.692\n",
      "Epoch 4/5.. Train loss: 0.297.. Test loss: 1.246.. Test accuracy: 0.677\n",
      "Epoch 4/5.. Train loss: 0.210.. Test loss: 1.124.. Test accuracy: 0.698\n",
      "Epoch 5/5.. Train loss: 0.234.. Test loss: 1.285.. Test accuracy: 0.696\n",
      "Epoch 5/5.. Train loss: 0.333.. Test loss: 1.329.. Test accuracy: 0.697\n",
      "Epoch 5/5.. Train loss: 0.223.. Test loss: 1.277.. Test accuracy: 0.707\n",
      "Epoch 5/5.. Train loss: 0.324.. Test loss: 1.236.. Test accuracy: 0.712\n",
      "Epoch 5/5.. Train loss: 0.239.. Test loss: 1.361.. Test accuracy: 0.708\n",
      "Epoch 5/5.. Train loss: 0.318.. Test loss: 1.473.. Test accuracy: 0.702\n",
      "Epoch 5/5.. Train loss: 0.310.. Test loss: 1.748.. Test accuracy: 0.694\n",
      "Epoch 5/5.. Train loss: 0.214.. Test loss: 1.452.. Test accuracy: 0.700\n",
      "Epoch 5/5.. Train loss: 0.382.. Test loss: 1.264.. Test accuracy: 0.716\n",
      "Epoch 5/5.. Train loss: 0.331.. Test loss: 1.347.. Test accuracy: 0.674\n",
      "Epoch 5/5.. Train loss: 0.211.. Test loss: 1.591.. Test accuracy: 0.641\n",
      "Epoch 5/5.. Train loss: 0.224.. Test loss: 1.267.. Test accuracy: 0.682\n",
      "Epoch 5/5.. Train loss: 0.229.. Test loss: 1.253.. Test accuracy: 0.702\n",
      "Epoch 5/5.. Train loss: 0.316.. Test loss: 1.316.. Test accuracy: 0.703\n",
      "Epoch 5/5.. Train loss: 0.226.. Test loss: 1.447.. Test accuracy: 0.706\n",
      "Epoch 5/5.. Train loss: 0.310.. Test loss: 1.762.. Test accuracy: 0.669\n",
      "Epoch 5/5.. Train loss: 0.397.. Test loss: 1.371.. Test accuracy: 0.710\n",
      "Epoch 5/5.. Train loss: 0.331.. Test loss: 1.010.. Test accuracy: 0.699\n",
      "Epoch 5/5.. Train loss: 0.271.. Test loss: 1.062.. Test accuracy: 0.710\n",
      "Epoch 5/5.. Train loss: 0.245.. Test loss: 1.317.. Test accuracy: 0.699\n",
      "Epoch 5/5.. Train loss: 0.229.. Test loss: 1.770.. Test accuracy: 0.640\n",
      "Epoch 5/5.. Train loss: 0.214.. Test loss: 1.858.. Test accuracy: 0.662\n",
      "Epoch 5/5.. Train loss: 0.203.. Test loss: 1.729.. Test accuracy: 0.692\n",
      "Epoch 5/5.. Train loss: 0.223.. Test loss: 1.334.. Test accuracy: 0.707\n",
      "Epoch 5/5.. Train loss: 0.289.. Test loss: 1.206.. Test accuracy: 0.731\n",
      "Epoch 5/5.. Train loss: 0.259.. Test loss: 1.291.. Test accuracy: 0.728\n",
      "Epoch 5/5.. Train loss: 0.261.. Test loss: 1.457.. Test accuracy: 0.698\n",
      "Epoch 5/5.. Train loss: 0.344.. Test loss: 1.236.. Test accuracy: 0.712\n",
      "Epoch 5/5.. Train loss: 0.306.. Test loss: 1.291.. Test accuracy: 0.711\n",
      "Epoch 5/5.. Train loss: 0.242.. Test loss: 1.194.. Test accuracy: 0.732\n",
      "Epoch 5/5.. Train loss: 0.273.. Test loss: 1.396.. Test accuracy: 0.691\n",
      "Epoch 5/5.. Train loss: 0.175.. Test loss: 1.642.. Test accuracy: 0.685\n",
      "Epoch 5/5.. Train loss: 0.297.. Test loss: 1.571.. Test accuracy: 0.697\n",
      "Epoch 5/5.. Train loss: 0.311.. Test loss: 0.843.. Test accuracy: 0.747\n",
      "Epoch 5/5.. Train loss: 0.318.. Test loss: 0.838.. Test accuracy: 0.737\n",
      "Epoch 5/5.. Train loss: 0.162.. Test loss: 1.277.. Test accuracy: 0.649\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "max_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        \n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    if accuracy >= max_accuracy:\n",
    "                        max_accuracy = accuracy\n",
    "                        torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "checked-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../Model_files/resnet18luca.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "trying-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1:150528, 3:50176, 224:224, 224:1, requires_grad=0, device=cpu),\n",
      "      %fc.0.weight : Float(10:512, 512:1, requires_grad=1, device=cpu),\n",
      "      %fc.0.bias : Float(10:1, requires_grad=1, device=cpu),\n",
      "      %fc.3.weight : Float(3:10, 10:1, requires_grad=1, device=cpu),\n",
      "      %fc.3.bias : Float(3:1, requires_grad=1, device=cpu),\n",
      "      %198 : Float(64:147, 3:49, 7:7, 7:1, requires_grad=0, device=cpu),\n",
      "      %199 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %201 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %202 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %204 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %205 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %207 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %208 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %210 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %211 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %213 : Float(128:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %214 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %216 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %217 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %219 : Float(128:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %220 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %222 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %223 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %225 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %226 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %228 : Float(256:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %229 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %231 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %232 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %234 : Float(256:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %235 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %237 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %238 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %240 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %241 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %243 : Float(512:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %244 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %246 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %247 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %249 : Float(512:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %250 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %252 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %253 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %255 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %256 : Float(512:1, requires_grad=0, device=cpu)):\n",
      "  %197 : Float(1:802816, 64:12544, 112:112, 112:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input, %198, %199)\n",
      "  %127 : Float(1:802816, 64:12544, 112:112, 112:1, requires_grad=0, device=cpu) = onnx::Relu(%197) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %128 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%127) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:586:0\n",
      "  %200 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%128, %201, %202)\n",
      "  %131 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Relu(%200) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %203 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%131, %204, %205)\n",
      "  %134 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Add(%203, %128)\n",
      "  %135 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Relu(%134) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %206 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%135, %207, %208)\n",
      "  %138 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Relu(%206) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %209 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%138, %210, %211)\n",
      "  %141 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Add(%209, %135)\n",
      "  %142 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=0, device=cpu) = onnx::Relu(%141) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %212 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%142, %213, %214)\n",
      "  %145 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Relu(%212) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %215 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%145, %216, %217)\n",
      "  %218 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%142, %219, %220)\n",
      "  %150 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Add(%215, %218)\n",
      "  %151 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Relu(%150) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %221 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%151, %222, %223)\n",
      "  %154 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Relu(%221) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %224 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%154, %225, %226)\n",
      "  %157 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Add(%224, %151)\n",
      "  %158 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=0, device=cpu) = onnx::Relu(%157) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %227 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%158, %228, %229)\n",
      "  %161 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Relu(%227) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %230 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%161, %231, %232)\n",
      "  %233 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%158, %234, %235)\n",
      "  %166 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Add(%230, %233)\n",
      "  %167 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Relu(%166) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %236 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%167, %237, %238)\n",
      "  %170 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Relu(%236) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %239 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%170, %240, %241)\n",
      "  %173 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Add(%239, %167)\n",
      "  %174 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=0, device=cpu) = onnx::Relu(%173) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %242 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%174, %243, %244)\n",
      "  %177 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Relu(%242) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %245 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%177, %246, %247)\n",
      "  %248 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%174, %249, %250)\n",
      "  %182 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Add(%245, %248)\n",
      "  %183 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Relu(%182) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %251 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%183, %252, %253)\n",
      "  %186 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Relu(%251) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %254 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%186, %255, %256)\n",
      "  %189 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Add(%254, %183)\n",
      "  %190 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=0, device=cpu) = onnx::Relu(%189) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %191 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = onnx::GlobalAveragePool(%190) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %192 : Float(1:512, 512:1, requires_grad=0, device=cpu) = onnx::Flatten[axis=1](%191) # /opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py:214:0\n",
      "  %193 : Float(1:10, 10:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%192, %fc.0.weight, %fc.0.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1690:0\n",
      "  %194 : Float(1:10, 10:1, requires_grad=1, device=cpu) = onnx::Relu(%193) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:983:0\n",
      "  %195 : Float(1:3, 3:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%194, %fc.3.weight, %fc.3.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1690:0\n",
      "  %output : Float(1:3, 3:1, requires_grad=1, device=cpu) = onnx::LogSoftmax[axis=1](%195) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1605:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dummy_input = Variable(torch.randn(1, 3, 224, 224)) \n",
    "\n",
    "torch.onnx.export(model,\n",
    "                  dummy_input,\n",
    "                  \"../Model_files/resnet18_luca2.onnx\",\n",
    "                  verbose=True,\n",
    "                    input_names=[\"input\"],\n",
    "                    output_names=[\"output\"],\n",
    "                    opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fantastic-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image = 'image.jpg'\n",
    "prepro_image = preprocess(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "conscious-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_mask': 0, 'mask': 1, 'no_mask': 2}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = '../../dataset/train/'\n",
    "\n",
    "\n",
    "\n",
    "trainset = datasets.ImageFolder(train_data_dir, transform=preprocess)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "quantitative-regulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(iter(trainloader))\n",
    "image = inputs[0]\n",
    "pred = labels[0]\n",
    "\n",
    "image = image.view(1, 3, 224, 224)\n",
    "model(image)[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "naughty-recognition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.7754, -1.7583, -1.7754,  ..., -1.3130, -1.2959, -1.3130],\n",
       "          [-1.7925, -1.7925, -1.7754,  ..., -1.3130, -1.2959, -1.3130],\n",
       "          [-1.8097, -1.8268, -1.7925,  ..., -1.2617, -1.2617, -1.2788],\n",
       "          ...,\n",
       "          [-1.4672, -1.5014, -1.5870,  ..., -1.7754, -1.7583, -1.7412],\n",
       "          [-1.5528, -1.5014, -1.5185,  ..., -1.7925, -1.7583, -1.7412],\n",
       "          [-1.6384, -1.5014, -1.4843,  ..., -1.8268, -1.7754, -1.7412]],\n",
       "\n",
       "         [[-1.7381, -1.7031, -1.7031,  ..., -0.8627, -0.8452, -0.8277],\n",
       "          [-1.7556, -1.7381, -1.7206,  ..., -0.8452, -0.8277, -0.7927],\n",
       "          [-1.7556, -1.7731, -1.7381,  ..., -0.8277, -0.8102, -0.7402],\n",
       "          ...,\n",
       "          [-1.3529, -1.3354, -1.4580,  ..., -1.7381, -1.7206, -1.7031],\n",
       "          [-1.4580, -1.3704, -1.3880,  ..., -1.7556, -1.7206, -1.7031],\n",
       "          [-1.5630, -1.4055, -1.3704,  ..., -1.7906, -1.7556, -1.7031]],\n",
       "\n",
       "         [[-1.1944, -1.2119, -1.2467,  ..., -0.2358, -0.2010, -0.2358],\n",
       "          [-1.2293, -1.2467, -1.2641,  ..., -0.3230, -0.2881, -0.3055],\n",
       "          [-1.2990, -1.3164, -1.2816,  ..., -0.2881, -0.2707, -0.2881],\n",
       "          ...,\n",
       "          [-0.8110, -0.8458, -1.0201,  ..., -1.2119, -1.1421, -1.1596],\n",
       "          [-0.9678, -0.9330, -1.0376,  ..., -1.1944, -1.1247, -1.1247],\n",
       "          [-1.0898, -0.9853, -1.0376,  ..., -1.2293, -1.1421, -1.1073]]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
